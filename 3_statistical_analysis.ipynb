{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "634d32c5-4788-4036-96a1-6703e2fd4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running the notebook on Google Colab, uncomment the following lines of code.\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/MyDrive/CSMM-pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839bb2dd-8940-4a0e-a3d0-d78c38eb6356",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576bd73e-13e5-4ce0-94ed-e18e3ad3c7fd",
   "metadata": {},
   "source": [
    "After training the machine learning classifiers, we would like to use them to quantify our variables of interest (e.g., argumentation strategy) in the entire corpus. Even when classifiers meet certain quality criteria (e.g., high F1 score), some residual classification error remains. As such, variables quantified through machine learning can confound the statistical analyses.\n",
    "\n",
    "In the following we introduce two techniques for preventing bias through machine classification in the statistical analyses, especially for <b>settings in which we would like to compare between two groups</b> (e.g., opinion strategy vs. no opinion) and in which groups are not randomly assigned, but identified through classifier labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5553c0-b9a8-44aa-aa41-18b34f62ebc7",
   "metadata": {},
   "source": [
    "## Accounting for Classifier Inaccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0d9b0-7560-47f1-9043-3343fab151c1",
   "metadata": {},
   "source": [
    "For the following example, let's assume that we'd like to investigate whether tweets containing argumentation strategy opinion are also less hateful than tweets not containing opinion. We will need to define a classifier threshold to distinguish tweets with \"opinion\" from tweets with \"no opinion\".\n",
    "\n",
    "One possibility is to select tweets as \"opinion\" for which the classifier probability is the highest for \"opinion\" compared to other classes. However, this would also label tweets as opinion for which the classifier is actually not very confident (e.g., \"construct\": 0.25, \"opin\": 0.30, \"sarc\": 0.25, \"leave_fact\": 0.18, \"other\": 0.02).\n",
    "\n",
    "For the group comparison, we would rather like to only classify tweets as opinion for which the classifier is confident. In the following, we demonstrate how to tune the classification threshold against classifier F1 scores to make both classes maximally distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa96151-706f-4cec-9e78-6d088c05ff53",
   "metadata": {},
   "source": [
    "## Focus Group Comparisons: Binarizing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f848d0-e342-4899-8cd2-4ee5b8a7ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import softmax\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64f7eb9-c5f4-4034-850d-107cb6968aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb8d2b-43fa-4cf1-8f84-0967d12911d2",
   "metadata": {},
   "source": [
    "First, we need to find the best performing model for a certain classification task overall (e.g., classifying argumentation strategy). Remember: We trained models on five different data splits for the same task to select the best out of five (see also notebook on model training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ccadf8-82d5-4fd7-a542-7aae4005255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(src, model, class_dict):\n",
    "    \"\"\"\n",
    "    Finds the split that performs best in terms of macro avg F1 score over\n",
    "    all classes (for argumentation startegy) and returns the split number.\n",
    "    Assume we have already generated files with predictions of each of the\n",
    "    models (splits) for our test set (here in directory \"data/preds_strategy_test\").\n",
    "    \"\"\"\n",
    "    pred_files = os.listdir(Path(src, \"preds_strategy_test\"))\n",
    "    pred_files = [f for f in pred_files if model in f]\n",
    "    pred_files.sort()\n",
    "    \n",
    "    performances = pd.DataFrame()\n",
    "    for split in range(5):\n",
    "        # load raw predictions of classifier\n",
    "        preds = pd.read_csv(\n",
    "            Path(src, \"preds_strategy_test\", pred_files[split])\n",
    "        )\n",
    "        preds = preds.rename(columns={\"label\": \"true_label\"})\n",
    "        \n",
    "        # calculate performance metrics including F1 score\n",
    "        report = classification_report(\n",
    "            preds[\"true_label\"], \n",
    "            preds[\"pred_label\"], \n",
    "            output_dict=True,\n",
    "            zero_division = 0\n",
    "        )\n",
    "\n",
    "        # store model number and F1 score in \"performances\" dataframe\n",
    "        row = pd.DataFrame({\n",
    "            \"split\": [split], \n",
    "            \"f1-score\": [report[\"macro avg\"][\"f1-score\"]]\n",
    "        })\n",
    "        \n",
    "        performances = pd.concat([performances, row]).reset_index(drop=True)\n",
    "\n",
    "    # find best split based on F1 score\n",
    "    best_split = int(performances.loc[performances.idxmax()[\"f1-score\"]][\"split\"])\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c271a9-b581-4247-a069-606c8678b754",
   "metadata": {},
   "source": [
    "After finding the best performing model for argumentation strategy overall, we scan through different thresholds to distinguish \"opinion\" and \"not opinion\", calculating the F1 score with respect to the human annotated test set for each of those thresholds. We would like to select the threshold for which the F1 score is the highest to make groups \"opinion\" and \"not opinion\" maximally distinct. We will consider all classifier thresholds between 0 and 1 in increments of 0.01. The table below illustrates this principle with a toy example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a3e75-a264-436a-b3e8-d46eaea9cda9",
   "metadata": {},
   "source": [
    "| Tweet        | Human       | Classifier probability | Threshold 0.73 | Threshold 0.74 |\n",
    "| ------------ | ----------- | ---------------------- | -------------- | -------------- |\n",
    "| Tweet A      | opinion     | .742                   | opinion        | opinion        |\n",
    "| Tweet B      | not opinion | .737                   | opinion        | not opinion    |\n",
    "| Tweet C      | opinion     | .741                   | opinion        | opinion        |\n",
    "| Tweet D      | opinion     | .739                   | opinion        | not opinion    |\n",
    "| Tweet E      | not opinion | .725                   | not opinion    | not opinion    |\n",
    "| Tweet F      | opinion     | .749                   | opinion        | opinion        |\n",
    "| Tweet G      | not opinion | .741                   | opinion        | opinion        |\n",
    "| Tweet H      | not opinion | .722                   | not opinion    | not opinion    |\n",
    "| **F1 score** |             |                        | **.8**         | .75            |\n",
    "\n",
    "<i>Note.</i> For each group comparison, we increment classifier thresholds by 0.01 computing F1 scores for each of those thresholds according to the human annotated test set. Here, only two out of many tested thresholds are illustrated. To separate the dataset into groups, we would choose the threshold maximizing the F1 score, here 0.73 for argumentation strategy \"opinion\" (toy example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44e2d86-50e1-4069-9880-a5c622cbb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define some more helper functions.\n",
    "\n",
    "def scan_thresholds(src, model, class_dict, split):\n",
    "    \"\"\"\n",
    "    Scans different thresholds for prediction probabilities to binarize \n",
    "    predictions. Returns the classifier performances for each threshold.\n",
    "    \"\"\"\n",
    "    # load raw predictions of classifier\n",
    "    pred_files = os.listdir(Path(src, \"preds_strategy_test\"))\n",
    "    pred_files = [f for f in pred_files if model in f]\n",
    "    pred_files.sort()\n",
    "    pred_cols = [f\"raw_pred_{i}\" for i in range(len(class_dict))]\n",
    "    preds = pd.read_csv(\n",
    "        Path(src, \"preds_strategy_test\", pred_files[split])\n",
    "    )\n",
    "    # apply softmax to turn raw predictions into probabilities\n",
    "    preds[pred_cols] = softmax(preds[pred_cols], axis=1)\n",
    "    preds = preds.rename(columns={\"label\": \"true_label\"})\n",
    "\n",
    "    # loop over thresholds from 0 to 1 in increments of 0.01\n",
    "    thresholds = np.arange(0, 1, 0.01)\n",
    "    performances = pd.DataFrame()\n",
    "    for label in range(len(class_dict)):  # test all classes\n",
    "        for threshold in thresholds:\n",
    "            true_label = np.where(preds[\"true_label\"] == label, 1, 0)\n",
    "            pred_label = np.where(preds[f\"raw_pred_{label}\"] > threshold, 1, 0)\n",
    "            # calculate metrics\n",
    "            report = classification_report(\n",
    "                true_label, \n",
    "                pred_label, \n",
    "                output_dict=True,\n",
    "                zero_division = 0\n",
    "            )\n",
    "\n",
    "            # store results in dataframe\n",
    "            row = pd.DataFrame({\n",
    "                \"label\": [label],\n",
    "                \"threshold\": [threshold],\n",
    "                \"precision\": [report[\"macro avg\"][\"precision\"]],\n",
    "                \"recall\": [report[\"macro avg\"][\"recall\"]],\n",
    "                \"f1-score\": [report[\"macro avg\"][\"f1-score\"]]\n",
    "            })\n",
    "            \n",
    "            performances = pd.concat([performances, row])\n",
    "\n",
    "    performances = performances.reset_index(drop=True)\n",
    "\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d249f3-b13f-40c1-bf07-d7a5f6f584b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_thresholds(performances, class_dict):\n",
    "    \"\"\"\n",
    "    Returns the optimum threshold for every class (in argmentation strategy)\n",
    "    including the F1 score, precision and recall of the classifier in a\n",
    "    one vs. all prediction scenario.\n",
    "    \"\"\"\n",
    "    optima = pd.DataFrame()\n",
    "    for label in class_dict.keys():\n",
    "        subset = performances[performances[\"label\"] == label]  # only keep entries in the \"performances\" dataframe with current label\n",
    "        idx = subset.idxmax()[\"f1-score\"]  # get maximum F1 score\n",
    "        optimum = subset.loc[idx]  # locate optimal row in df\n",
    "        optima = pd.concat([optima, pd.DataFrame(optimum).transpose()])  # add to overall df collecting optimal thresholds\n",
    "\n",
    "    optima[\"label\"] = optima[\"label\"].astype(int)\n",
    "    optima[\"label\"] = optima[\"label\"].replace(class_dict)  # substitute numerical with natural language labels\n",
    "    optima = optima.rename(columns={\"threshold\": \"optimum_threshold\"})\n",
    "\n",
    "    return optima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190449c8-b09e-43b9-9ea6-725e6946659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the functions, we can now search for the optimum threshold to binarize predictions\n",
    "# for all classes in argumentation strategy in a one vs. all other classes scenario.\n",
    "\n",
    "model = \"twitter-xlm-roberta-base_epochs-100_batchsize-64_strategy\"\n",
    "class_dict = {\n",
    "    0: \"construct\",\n",
    "    1: \"opin\",\n",
    "    2: \"sarc\",\n",
    "    3: \"leave_fact\",\n",
    "    4: \"other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b17684-0958-4ad2-95c4-71a79778807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for argumentation startegy overall is split 3.\n"
     ]
    }
   ],
   "source": [
    "# First, we retrieve the best out of five models for argumentation strategy overall.\n",
    "best_split = get_best_split(src, model, class_dict)\n",
    "print(f\"Best model for argumentation startegy overall is split {best_split}.\")\n",
    "# Second, we scan through the thresholds in increments of 0.01 for each of opinion - not opinion, construct - not construct, etc.\n",
    "performances = scan_thresholds(src, model, class_dict, best_split)\n",
    "# Third, we retrieve the thresholds where the F1 score is the highest for each of the classes.\n",
    "optima = get_optimal_thresholds(performances, class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5747a04-c1d5-42b0-bf52-b79efad7f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"label\", \"optimum_threshold\", \"f1-score\", \"precision\", \"recall\"]\n",
    "optima = optima[cols].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd457b7a-793d-43fd-9417-23d323cf1ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>optimum_threshold</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>construct</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.739928</td>\n",
       "      <td>0.713683</td>\n",
       "      <td>0.780287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opin</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.782448</td>\n",
       "      <td>0.789912</td>\n",
       "      <td>0.776485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarc</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.670686</td>\n",
       "      <td>0.663035</td>\n",
       "      <td>0.679363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leave_fact</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.839352</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.838074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.884361</td>\n",
       "      <td>0.907378</td>\n",
       "      <td>0.866389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  optimum_threshold  f1-score  precision    recall\n",
       "0   construct               0.27  0.739928   0.713683  0.780287\n",
       "1        opin               0.40  0.782448   0.789912  0.776485\n",
       "2        sarc               0.28  0.670686   0.663035  0.679363\n",
       "3  leave_fact               0.47  0.839352   0.840664  0.838074\n",
       "4       other               0.31  0.884361   0.907378  0.866389"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display optimal thresholds\n",
    "optima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cedd68-123e-4f1f-ae01-5888612b3840",
   "metadata": {},
   "source": [
    "## Focus Group Comparisons: Classifier Based Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f9898-40ea-465b-83ee-3e02a1fbb758",
   "metadata": {},
   "source": [
    "While tuning the classifier threshold solves the problem of dividing observations into classes, the classifiers are in principle still imprecise. Therefore, we propose incorporating the classifier's false positive and false negative rates in the bootstrapping procedure for calculating the confidence intervals in the statistical analaysis.\n",
    "\n",
    "For example, let's assume the false positive and false negative rates of our classifier for opinion are 0.25 and 0.125, respectively. We then flip the label \"opinion\" to \"no opinion\" in 12.5\\% of the cases, and the label \"no opinion\" to \"opinion\" in 25\\% of the cases. This way, we draw multiple samples with replacement, repeating the analysis (here a t-test) to compute confidence intervals for our estimators (here t-statistic and Cohen's d). These confidence intervals are inflated and make the statistical conclusions robust to the noise of the classifier.\n",
    "\n",
    "The following table illustrates the principle on a toy example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738fe600-5252-4ce9-ad54-87ba5515c559",
   "metadata": {},
   "source": [
    "| Tweet                  | Classifier Label | Sample 1        | Sample 2        | Sample 3        |\n",
    "| :--------------------- | :--------------- | :-------------- | :-------------- | :-------------- |\n",
    "| Tweet A                | opinion          | **not opinion** | opinion         | opinion         |\n",
    "| Tweet B                | not opinion      | **opinion**     | not opinion     | not opinion     |\n",
    "| Tweet C                | opinion          | opinion         | opinion         | **not opinion** |\n",
    "| Tweet D                | opinion          | opinion         | **not opinion** | opinion         |\n",
    "| Tweet E                | not opinion      | not opinion     | **opinion**     | **opinion**     |\n",
    "| Tweet F                | opinion          | opinion         | opinion         | opinion         |\n",
    "| Tweet G                | not opinion      | not opinion     | not opinion     | **opinion**     |\n",
    "| Tweet H                | not opinion      | **opinion**     | **opinion**     | not opinion     |\n",
    "| Regression coefficient |                  | .45             | .49             | .37             |\n",
    "| Confidence interval    |                  |                 | [.37 - .49]     |                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1e0b9-6194-4aea-9770-a6ba9ab3b60c",
   "metadata": {},
   "source": [
    "<i>Note.</i> We flip labels according to the false negative rates (\"opinion\" to \"not opinion\") and false positive rates (\"not opinion\" to \"opinion\") of our classifier. Here, flipped labels are marked in bold. For each sample, we compute coefficients resulting in an overall confidence interval over all samples. The approach makes the group comparison robust to the errors of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609e978-58be-41e5-8a53-b43bfe7a3221",
   "metadata": {},
   "source": [
    "In the following, let's apply this procedure to our hypothetical question: Are tweets containing opinion also less hateful compared to tweets without opinion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "513c3e1d-a942-45e0-bf1d-0ebf829a43da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alinaherderich/anaconda3/envs/CSMM-pipeline/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acbe7b25-e28e-48ce-8c24-f8ef780f1288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>960158527582097408</td>\n",
       "      <td>Das ist so nicht richtig.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837717128480444418</td>\n",
       "      <td>Man sollte die Drohungen von der ISIS Gruppe e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082375206319128576</td>\n",
       "      <td>Gerade gibt's in den USA eine Ausschreibung fü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013645930443235328</td>\n",
       "      <td>Horst los! Das Netz hat dein Angebot voll ange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031345564649172992</td>\n",
       "      <td>Und was jetzt? Müssen wir uns jetzt neben dem ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text\n",
       "0   960158527582097408                          Das ist so nicht richtig.\n",
       "1   837717128480444418  Man sollte die Drohungen von der ISIS Gruppe e...\n",
       "2  1082375206319128576  Gerade gibt's in den USA eine Ausschreibung fü...\n",
       "3  1013645930443235328  Horst los! Das Netz hat dein Angebot voll ange...\n",
       "4  1031345564649172992  Und was jetzt? Müssen wir uns jetzt neben dem ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll load a sample corpus of 1000 unlabeled tweets for our example.\n",
    "sample_corpus = pd.read_csv(\"data/sample_pool.csv\", sep=\";\", usecols=[\"tweet_id\", \"text\"])\n",
    "sample_corpus = sample_corpus[:1000]\n",
    "sample_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6387ca1a-7e95-4389-af3a-d51d952b85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to classify tweets with opinion versus no opinion (binary variable, independent variable) and extract a\n",
    "# hate score for each of the tweets (continuous variable, dependent variable). For no/opinion, let's use our classifier\n",
    "# from \"training on confident examples\" (notebook model training). For hate, we'll use a pre-trained German BERT from\n",
    "# Huggingface that was finetuned on a German hate speech dataset (see here: https://epub.oeaw.ac.at/0xc1aa5576_0x003a10d2.pdf).\n",
    "MODEL_STRATEGY = \"finetuned_models/twitter-xlm-roberta-base_split-1\"\n",
    "MODEL_HATE = \"deepset/bert-base-german-cased-hatespeech-GermEval18Coarse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "071c241e-9581-42a3-bb58-fb0e9742a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(feature=\"opinion\"):\n",
    "    \"\"\"\n",
    "    Runs classifiers specified in MODEL_STRATEGY and MODEL_HATE over\n",
    "    the sample corpus, respectively.\n",
    "\n",
    "    Parameter \"feature\" takes values \"opinion\" or \"hate\".\n",
    "    \"\"\"\n",
    "    # check if GPU is available to run the models\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():  # for Apple Silicon\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # load models\n",
    "    if feature == \"opinion\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_STRATEGY).to(device)\n",
    "    if feature == \"hate\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_HATE)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_HATE).to(device)\n",
    "\n",
    "    # predict\n",
    "    preds = []\n",
    "    \n",
    "    for t in tqdm(sample_corpus.text.to_list()):\n",
    "        inputs = tokenizer(t, truncation=True, padding=True, max_length=180, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "    \n",
    "        if device == \"mps\":\n",
    "            torch.mps.empty_cache()\n",
    "\n",
    "        preds.append(softmax(logits.cpu())[0][1])  # both \"opinion\" and \"hate\" correspond to label 1\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95d71717-592d-4013-bb7d-5de198adfa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█| 201/201 [00:00<00:00, 1848.23it/s, Materializing param=\n",
      "100%|███████████████████████████████████████| 1000/1000 [00:15<00:00, 65.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# infer opinion score for tweets and add as column to dataframe\n",
    "opinion_probs = inference(feature=\"opinion\")\n",
    "sample_corpus[\"opinion_probs\"] = opinion_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85dd5abd-6fe8-41f3-a383-99f75b9c4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█| 201/201 [00:00<00:00, 1863.13it/s, Materializing param=\n",
      "100%|███████████████████████████████████████| 1000/1000 [00:11<00:00, 89.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# infer hate score for tweets and add as column to dataframe\n",
    "hate = inference(feature=\"hate\")\n",
    "sample_corpus[\"hate\"] = hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "641eaa4a-8bd4-4ea0-86f2-73608e3f99df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>opinion_probs</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>960158527582097408</td>\n",
       "      <td>Das ist so nicht richtig.</td>\n",
       "      <td>0.183180</td>\n",
       "      <td>0.088122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837717128480444418</td>\n",
       "      <td>Man sollte die Drohungen von der ISIS Gruppe e...</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.014237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082375206319128576</td>\n",
       "      <td>Gerade gibt's in den USA eine Ausschreibung fü...</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>0.009567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013645930443235328</td>\n",
       "      <td>Horst los! Das Netz hat dein Angebot voll ange...</td>\n",
       "      <td>0.183041</td>\n",
       "      <td>0.014625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031345564649172992</td>\n",
       "      <td>Und was jetzt? Müssen wir uns jetzt neben dem ...</td>\n",
       "      <td>0.183387</td>\n",
       "      <td>0.008012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0   960158527582097408                          Das ist so nicht richtig.   \n",
       "1   837717128480444418  Man sollte die Drohungen von der ISIS Gruppe e...   \n",
       "2  1082375206319128576  Gerade gibt's in den USA eine Ausschreibung fü...   \n",
       "3  1013645930443235328  Horst los! Das Netz hat dein Angebot voll ange...   \n",
       "4  1031345564649172992  Und was jetzt? Müssen wir uns jetzt neben dem ...   \n",
       "\n",
       "   opinion_probs      hate  \n",
       "0       0.183180  0.088122  \n",
       "1       0.180528  0.014237  \n",
       "2       0.183795  0.009567  \n",
       "3       0.183041  0.014625  \n",
       "4       0.183387  0.008012  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30ba020e-0b97-45f5-9341-c665b3564173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/ww_9n13j1n3b2xg6jrj22hq40000gn/T/ipykernel_49615/2656433866.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  sample_corpus[\"opinion_binary\"] = sample_corpus[\"opinion_binary\"].replace({False: 0, True: 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>opinion_probs</th>\n",
       "      <th>hate</th>\n",
       "      <th>opinion_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>960158527582097408</td>\n",
       "      <td>Das ist so nicht richtig.</td>\n",
       "      <td>0.183180</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837717128480444418</td>\n",
       "      <td>Man sollte die Drohungen von der ISIS Gruppe e...</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.014237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082375206319128576</td>\n",
       "      <td>Gerade gibt's in den USA eine Ausschreibung fü...</td>\n",
       "      <td>0.183795</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013645930443235328</td>\n",
       "      <td>Horst los! Das Netz hat dein Angebot voll ange...</td>\n",
       "      <td>0.183041</td>\n",
       "      <td>0.014625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1031345564649172992</td>\n",
       "      <td>Und was jetzt? Müssen wir uns jetzt neben dem ...</td>\n",
       "      <td>0.183387</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0   960158527582097408                          Das ist so nicht richtig.   \n",
       "1   837717128480444418  Man sollte die Drohungen von der ISIS Gruppe e...   \n",
       "2  1082375206319128576  Gerade gibt's in den USA eine Ausschreibung fü...   \n",
       "3  1013645930443235328  Horst los! Das Netz hat dein Angebot voll ange...   \n",
       "4  1031345564649172992  Und was jetzt? Müssen wir uns jetzt neben dem ...   \n",
       "\n",
       "   opinion_probs      hate  opinion_binary  \n",
       "0       0.183180  0.088122               0  \n",
       "1       0.180528  0.014237               0  \n",
       "2       0.183795  0.009567               0  \n",
       "3       0.183041  0.014625               0  \n",
       "4       0.183387  0.008012               0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usually, we would now use our threshold inferred from the data as demonstrated above\n",
    "# to assign tweets to the \"opinion\" versus \"no opinion\" class. However,\n",
    "# since we are working with a (very bad performing) preliminary classifier, for demonstration\n",
    "# purposes, let's set the cut-off score arbitrarily such that approximately half of the tweets\n",
    "# are assigned to \"opinion\" and \"no opinion\".\n",
    "sample_corpus[\"opinion_binary\"] = np.array(opinion_probs) > 0.221  # arbitrary cut-off for demonstration only!\n",
    "sample_corpus[\"opinion_binary\"] = sample_corpus[\"opinion_binary\"].replace({False: 0, True: 1})\n",
    "sample_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9531738e-9696-47a7-968b-6521ecd32658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_label  pred_label\n",
       "0           1           1\n",
       "1           3           3\n",
       "2           1           3\n",
       "3           3           1\n",
       "4           1           1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the false positive (FPR) and false negative rate (FNR), we will rely on the \n",
    "# true and predicted scores for opinion on our test set for the best performing model\n",
    "# (see above). We will need the FPR and FNR for bootstrapping statistical parameters\n",
    "# in the group comparisons later.\n",
    "testset = pd.read_csv(\"data/preds_strategy_test/twitter-xlm-roberta-base_epochs-100_batchsize-64_strategy_split-3_preds.csv\")\n",
    "testset = testset[[\"label\", \"pred_label\"]].rename(columns={\"label\": \"true_label\"})\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5488b6c-8c97-45bb-b139-75cfad52e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,  19,   0,  11,   6],\n",
       "       [ 16, 133,   1,  28,   9],\n",
       "       [ 10,  11,   2,   8,   6],\n",
       "       [  3,  25,   1, 131,   4],\n",
       "       [  9,  15,   0,   7, 113]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(testset.true_label, testset.pred_label)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f78410e8-210b-4651-bd91-859d5ffa6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1, 1]\n",
    "FN = confusion[1, :].sum() - TP\n",
    "FP = confusion[:, 1].sum() - TP\n",
    "TN = len(testset) - FN - FN - FP\n",
    "\n",
    "FPR = FP / (FP + TN)  # 0.14\n",
    "FNR = FN / (FN + TP)  # 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3897a82-9bf2-4ee8-a183-0f76c0b8b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can bootstrap our statistics: t and Cohen's d.\n",
    "\n",
    "def cohens_d(A, B):\n",
    "    \"\"\"\n",
    "    Calculates Cohen's d as effect size for the t test of independent samples\n",
    "    A and B with different sample sizes and different variances.\n",
    "    \"\"\"\n",
    "    n1 = len(A)\n",
    "    n2 = len(B)\n",
    "    var1 = A.var()\n",
    "    var2 = B.var()\n",
    "    mean1 = A.mean()\n",
    "    mean2 = B.mean()\n",
    "    \n",
    "    sd_pooled = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    \n",
    "    d = (mean1 - mean2) / sd_pooled\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1c25dc0-b096-43fd-bbdc-40e72472e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:01<00:00, 769.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# We will run the t-test for a thousand times flipping the label opinion to no opinion based\n",
    "# on the false positive rate and no opinion to opinion on the false negative rate. We'll collect\n",
    "# the t statistic and the Cohen's d for each of those runs to plot them afterwards.\n",
    "BOOT = 1000\n",
    "\n",
    "summary_t = []\n",
    "summary_d = []\n",
    "\n",
    "for i in tqdm(range(BOOT)):\n",
    "    # sample indices for flipping labels\n",
    "    flip_positive = pd.Series(sample_corpus.index[sample_corpus.opinion_binary == 1]).sample(frac=FPR, random_state=i)\n",
    "    flip_negative = pd.Series(sample_corpus.index[sample_corpus.opinion_binary == 0]).sample(frac=FNR, random_state=i)\n",
    "\n",
    "    # flip labels\n",
    "    temp = sample_corpus.copy()\n",
    "    temp.loc[flip_positive, \"opinion_binary\"] = 0\n",
    "    temp.loc[flip_negative, \"opinion_binary\"] = 1\n",
    "\n",
    "    # compute statistics\n",
    "    t, p = stats.ttest_ind(temp[temp.opinion_binary == 0].hate, temp[temp.opinion_binary == 1].hate)\n",
    "    d = cohens_d(temp[temp.opinion_binary == 0].hate, temp[temp.opinion_binary == 1].hate)\n",
    "\n",
    "    summary_t.append(t)\n",
    "    summary_d.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e1429af-4ad4-4023-a292-b37100c5f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of t statistics\n",
    "# The vertical line denotes the cut of score for an alpha level of 0.05.\n",
    "# Here, we can make the robust conclusion that the two groups (opinion vs.\n",
    "# no opinion) differ only when all bootstrapped tests exceed the significance level.\n",
    "plt.hist(summary_t, bins=np.arange(np.min(summary_t), np.max(summary_t), 0.25), color='teal')\n",
    "plt.vlines(1.96, ymin=0, ymax=150, color='darkorange', linestyle='--')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac684da3-6f9f-4219-81c5-603ce598d69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cohen's d denotes the size and direction of the difference between\n",
    "# the two groups (opinion vs. no opinion). Note: These results are not\n",
    "# reliable based on our very bad performing classifiers that we used to\n",
    "# extract the variables and just for illustration purposes.\n",
    "plt.hist(summary_d, bins=np.arange(np.min(summary_d), np.max(summary_d), 0.05), color='teal')\n",
    "plt.xlabel('d')\n",
    "plt.ylabel('frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ea33f-2161-497a-94bd-1f565cc8d1d3",
   "metadata": {},
   "source": [
    "<b>Congratulations, you've reached the end of the tutorial!</b>\n",
    "\n",
    "If you'd like to dive deeper into the concepts discussed in this tutorial, please refer to the accompanying publication: Herderich, A., Lasser, J., Galesic, M., Aroyehun, S., David, G., & Garland, J. (2026). Measuring complex constructs in large-scale text with computational social mixed methods. <i>BRM, under review</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1c0c8-b27d-4789-8e89-c260c54804f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
