{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febb4d1a-1b40-4673-a115-52f42d142100",
   "metadata": {},
   "source": [
    "# Key Problem II: LLMs as classification models\n",
    "# Depending on concept ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a51b95-dc66-416d-bd78-9293c01df7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4548898a-94b3-4094-8946-c6dde1a0d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to run (some part of) this code, please insert your personal Open AI API Key here\n",
    "client = OpenAI(api_key=\"YOUR API KEY HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad4cf1-af6d-49fc-be3e-290f3173a144",
   "metadata": {},
   "source": [
    "## Defining global variables\n",
    "In the following we define the codebook for prompting GPT-4, and assign numerical to natural language codes for the classes, we'd like GPT-4 to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625c31f3-ae91-4294-bff2-d129932c4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODEBOOK = \"You are a data labeler, here are the labels and instructions of each label:\\n\\n\\\n",
    "1: exclusionary about outgroup'; which is assigned if the text points out realistic \\\n",
    "or unrealistic threats from the outgroup, or if the text makes members of the \\\n",
    "outgroup look stupid\\n\\\n",
    "'0: inclusionary about in/both groups'; which is assigned if the text highlights \\\n",
    "positive characteristics of the ingroup or justifies their actions, or if the \\\n",
    "text is pointing out common characteristics or challenges of in- and outgroup\\n\\\n",
    "'2: other'; which is assigned if the text does not have in- or outgroup thinking, \\\n",
    "or if the text has signs of in- or outgroup thinking, but the speaker's affiliation \\\n",
    "is not apparent.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5d44b4-ed85-4725-8a5e-c60097956ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL_MAP = {0: \"inclusionary about in/both groups\",\n",
    "            1: \"exclusionary about out-group\",\n",
    "            2: \"other\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad93774-450f-4eb4-8a00-c918048488f6",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "The training dataset are samples that we randomly draw from to provide examples to GPT-4 while prompting. The test dataset are samples that GPT-4 is supposed to annotate and where we know the true label based on human annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c020bd3-4d16-41ec-8f53-f9bd476d9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_goal_data():\n",
    "    training_data = pd.read_csv(\"data/goal_train_for_LLM.csv\", delimiter=\";\")\n",
    "    test_data = pd.read_csv(\"data/goal_test_for_LLM.csv\", delimiter=\";\")\n",
    "\n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f43a57-6275-4cce-bb36-42525acb2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = read_goal_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de009c-f7e2-4e81-a760-793117a3b655",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383a6808-4a79-46e6-9a60-454b7d67d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_training_sample(training_data):\n",
    "    \"\"\" Chooses random examples for all three classes from the training data for prompting \"\"\"\n",
    "    df0 = training_data.query('label==0').sample(n=1)\n",
    "    df1 = training_data.query('label==1').sample(n=1)\n",
    "    df2 = training_data.query('label==2').sample(n=1)\n",
    "    \n",
    "    return pd.concat([df0, df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc566f8-a0ea-4120-b240-c13834d388ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_test_sample(test_data):\n",
    "    \"\"\" Draws one sample from the test data for labeling \"\"\"\n",
    "    df0 = test_data.sample(n=1)\n",
    "    \n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0493b5f2-b10e-4540-9930-e2e2219758b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_labels_from_response_text(resp_data):\n",
    "    \"\"\" Extracts numerical labels from GPT-4s response messages \"\"\"\n",
    "    if \"0\" in resp_data[\"response_message\"] or \"inclusionary\" in resp_data[\"response_message\"]:\n",
    "        label = \"0\"\n",
    "    elif \"1\" in resp_data[\"response_message\"] or \"exclusionary\" in resp_data[\"response_message\"]:\n",
    "        label = \"1\"\n",
    "    elif \"2\" in resp_data[\"response_message\"] or \"other\" in resp_data[\"response_message\"]:\n",
    "        label = \"2\"\n",
    "    else:\n",
    "        print(\"Label not found!\", resp_data[\"response_message\"])\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a3d6ca-0a64-4507-b871-aed469dae968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_F1_scores(filename):\n",
    "    \"\"\" Computes the micro and macro F1 scores for GPT-4s performance \"\"\"\n",
    "    y_true = []\n",
    "    y_pred = [] \n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            resp_data = json.loads(line)\n",
    "            predicted_label = infer_labels_from_response_text(resp_data)\n",
    "            y_true.append(resp_data[\"true_label\"])\n",
    "            y_pred.append(predicted_label)\n",
    "            \n",
    "    print(\"macro\", f1_score(y_true, y_pred, average='macro'))\n",
    "    print(\"micro\", f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837a4db-2c9f-47da-95a3-8e02a52b3679",
   "metadata": {},
   "source": [
    "## Prompting example\n",
    "To illustrate, let's print an exemplary prompt for GPT-4 in a few shot setting, without codebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137d69aa-448b-429b-86df-483f666f8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prompting_ex(training_data, test_data):\n",
    "\n",
    "    training_data, test_data = read_goal_data()\n",
    "\n",
    "    random_few_shot_training = choose_random_training_sample(training_data)\n",
    "    test_sample = choose_random_test_sample(test_data)\n",
    "\n",
    "    print(\"You are a data labeler, here are the labels:\\n\\n\\\n",
    "0: inclusionary about in or both groups\\n\\\n",
    "1: exclusionary about out-group\\n\\\n",
    "2: other\\n\\n\\\n",
    "Here are a few examples:\\n\")\n",
    "\n",
    "    for _, row in random_few_shot_training.iterrows():\n",
    "        print(row[\"text\"], f\"// This is labeled as {GOAL_MAP[row['label']]}.\")\n",
    "\n",
    "    print(\"\\nPlease label this message:\", test_sample[\"text\"].values[0])\\\n",
    "    \n",
    "    print(\"\\n***TRUE LABEL***\", test_sample[\"label\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fbf450-83c6-4a90-9b56-dddbe5521cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a data labeler, here are the labels:\n",
      "\n",
      "0: inclusionary about in or both groups\n",
      "1: exclusionary about out-group\n",
      "2: other\n",
      "\n",
      "Here are a few examples:\n",
      "\n",
      "Quatsch. Europa fällt wegen der Flüchtlingsfrage auseinander. Schau mal richtig hin, Herr @xyz123. Alles geht den Bach runter. // This is labeled as inclusionary about in/both groups.\n",
      "Für solche Aussagen gibt’s in der Türkei bald die Todesstrafe. Da ist dann mit Meinungsfreiheit echt Schluss. @randomUser123 // This is labeled as exclusionary about out-group.\n",
      "1. Weil er @falschername die Trümmertruppe in Gefahr bringt.  \n",
      "2. A. Murksel schafft es nicht, die gewählten Leute zu beschützen.  \n",
      "3. Im Gegensatz zu Recep kauft er keine Panzer.  \n",
      "4. Er muss erledigt werden – sonst könnten andere dem folgen.  \n",
      "5. Er hat sich nicht als syrischer 14-jähriger Flüchtling ausgegeben. // This is labeled as other.\n",
      "\n",
      "Please label this message: Die spd kann nicht nein sagen, weil rwe Jobs für Gewerkschaften bietet, sonst verlieren sie eigene Fans. ;) @coolaccount123\n",
      "\n",
      "***TRUE LABEL*** 1\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompting_ex(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c21240-22ad-4892-a6a1-65b54e3f6923",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "In the following, we run three experiments to evaluate GPT-4s performance in different settings: 1) Zero shot with codebook, 2) Few shot without codebook, 3) Few shot with codebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e84c8-5192-4126-bd17-047d8b9a947b",
   "metadata": {},
   "source": [
    "### Experiment 1: Zero shot, with codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f41969a6-d7e5-45de-a17b-b6576ecb38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_with_codebook():\n",
    "    training_data, test_data = read_goal_data()\n",
    "\n",
    "    random_few_shot_training = choose_random_training_sample(training_data)\n",
    "    test_sample = choose_random_test_sample(test_data)\n",
    "\n",
    "    extra_instr = \"Using these labels and instructions please label the following text: \"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": CODEBOOK\n",
    "                    },\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": extra_instr + test_sample[\"text\"].values[0]\n",
    "                    },\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "                )\n",
    "    \n",
    "    print(response)\n",
    "    print(\"\\n\\n****TRUE LABEL***\",test_sample[\"label\"].values[0])\n",
    "    \n",
    "    return {\"response_message\": response.choices[0].message.content,\n",
    "            \"true_label\": str(test_sample[\"label\"].values[0]),\n",
    "            \"tweet_id\": str(test_sample[\"tweet_id\"].values[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ccf5b77-2440-4a7a-a781-58358dfa3cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro 0.5017320339563031\n",
      "micro 0.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment 1: 100 trials\n",
    "Zero Shot: codebook provided but no examples\n",
    "\n",
    "Note: The following code reads the results from our experiments. To rerun the experiment,\n",
    "un-comment the code. You might want to choose another file name to separate your results from\n",
    "ours before running the code.\n",
    "\"\"\"\n",
    "\n",
    "trials = 100\n",
    "output_file_name = \"results/zero_shot_w_code.jsona\"\n",
    "\n",
    "#for i in tqdm(range(trials), total=trials):\n",
    "#    predicted_label = zero_shot_with_codebook()\n",
    "    \n",
    "#    with open(output_file_name, \"a\") as f:\n",
    "#        json.dump(predicted_label, f)\n",
    "    \n",
    "#    with open(output_file_name, \"a\") as f:\n",
    "#        f.write(\"\\n\")\n",
    "\n",
    "compute_F1_scores(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a08f612b-d9a7-4117-84fa-4f3f30eeced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CfwdNMHDHltbRGpa2mlYl5mKLUk3I', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1: exclusionary about outgroup', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1764112873, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=209, total_tokens=216, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "\n",
      "****TRUE LABEL*** 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response_message': '1: exclusionary about outgroup',\n",
       " 'true_label': '1',\n",
       " 'tweet_id': '859516817726943232'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell for an example output\n",
    "# Comment out if API Key not available\n",
    "zero_shot_with_codebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea017e8-ef0b-461d-b9a7-92af682d4599",
   "metadata": {},
   "source": [
    "### Experiment 2: Few shot, without codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9adaaf93-dbfa-40e6-8bd5-f435057d8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_without_codebook():\n",
    "    training_data, test_data = read_goal_data()\n",
    "\n",
    "    random_few_shot_training = choose_random_training_sample(training_data)\n",
    "    test_sample = choose_random_test_sample(test_data)\n",
    "    examples_str = \"\"\n",
    "    \n",
    "    for _, row in random_few_shot_training.iterrows():\n",
    "        examples_str = examples_str + row[\"text\"] + f\" // This is labeled as {GOAL_MAP[row['label']]}.\\n\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a data labeler, here are the labels:\\n\\n \\\n",
    "                                0: inclusionary about in or both groups\\n \\\n",
    "                                1: exclusionary about out-group\\n \\\n",
    "                                2: other \\n \\\n",
    "                                Here are a few examples: \" + examples_str\n",
    "                    },\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Please label this message: \" + test_sample[\"text\"].values[0]\n",
    "                    },\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "                )\n",
    "    \n",
    "    print(response)\n",
    "    print(\"\\n\\n***TRUE LABEL***\", test_sample[\"label\"].values[0])\n",
    "    \n",
    "    return {\"response_message\": response.choices[0].message.content,\n",
    "            \"true_label\": str(test_sample[\"label\"].values[0]),\n",
    "            \"tweet_id\": str(test_sample[\"tweet_id\"].values[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537c2c62-65a5-49f6-b4a8-3cff9b4e0635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro 0.625756831942399\n",
      "micro 0.65\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment 2: 100 trials\n",
    "3 Random training examples are given with short labels (defined in func), no codebook\n",
    "\n",
    "Note: The following code reads the results from our experiments. To rerun the experiment,\n",
    "un-comment the code. You might want to choose another file name to separate your results from\n",
    "ours before running the code.\n",
    "\"\"\"\n",
    "\n",
    "trials = 100\n",
    "output_file_name = \"results/few_shot_no_code.jsona\"\n",
    "\n",
    "#for i in tqdm(range(trials),total=trials):\n",
    "#    predicted_label = few_shot_without_codebook()\n",
    "    \n",
    "#    with open(output_file_name, \"a\") as f:\n",
    "#        json.dump(predicted_label, f)\n",
    "    \n",
    "#    with open(output_file_name, \"a\") as f:\n",
    "#        f.write(\"\\n\")\n",
    "\n",
    "compute_F1_scores(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42241492-cda5-470e-813f-a03f82e2a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CfwdPqj1PDvwCsyJ4VaftvHbiHEtr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is labeled as exclusionary about out-group.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1764112875, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=290, total_tokens=300, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "\n",
      "***TRUE LABEL*** 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response_message': 'This is labeled as exclusionary about out-group.',\n",
       " 'true_label': '1',\n",
       " 'tweet_id': '574259885254307840'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell for an example output\n",
    "# Comment out if API Key not available\n",
    "few_shot_without_codebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847498a3-3c69-49d3-836a-d38baf3777b0",
   "metadata": {},
   "source": [
    "### Experiment 3: Few shot, with codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f92b875-4ef3-4aeb-9771-7e06167f46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_with_codebook():\n",
    "    training_data, test_data = read_goal_data()\n",
    "\n",
    "    random_few_shot_training = choose_random_training_sample(training_data)\n",
    "    test_sample = choose_random_test_sample(test_data)\n",
    "    examples_str = \"\"\n",
    "    \n",
    "    for _, row in random_few_shot_training.iterrows():\n",
    "        examples_str = examples_str + row[\"text\"] + f\" // This is labeled as {GOAL_MAP[row['label']]}.\\n\"\n",
    "\n",
    "    extra_instr = \"Using these labels, instructions and examples please label the following text: \"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": CODEBOOK + \"Here are a few examples: \" + examples_str\n",
    "                    },\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": extra_instr + test_sample[\"text\"].values[0]\n",
    "                    },\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=256,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "                )\n",
    "    \n",
    "    print(response)\n",
    "    print(\"\\n\\n****TRUE LABEL***\",test_sample[\"label\"].values[0])\n",
    "    \n",
    "    return {\"response_message\": response.choices[0].message.content,\n",
    "            \"true_label\": str(test_sample[\"label\"].values[0]),\n",
    "            \"tweet_id\": str(test_sample[\"tweet_id\"].values[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c77d96a8-3516-427e-9290-ee2621e02a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro 0.4291982745798007\n",
      "micro 0.6138613861386139\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Experiment 3: 100 trials\n",
    "3 Random training examples are given with labels and codebook is provided as context\n",
    "\n",
    "Note: The following code reads the results from our experiments. To rerun the experiment,\n",
    "un-comment the code. You might want to choose another file name to separate your results from\n",
    "ours before running the code.\n",
    "\"\"\"\n",
    "\n",
    "trials = 100\n",
    "output_file_name = \"results/few_shot_w_code.jsona\"\n",
    "\n",
    "#for i in tqdm(range(trials),total=trials):\n",
    "#    predicted_label = few_shot_with_codebook()\n",
    "    \n",
    "#    with open(output_file_name, \"a\") as f:\n",
    "#        json.dump(predicted_label, f)\n",
    "    \n",
    "#    with open(output_file_name, \"a\") as f:\n",
    "#        f.write(\"\\n\")\n",
    "\n",
    "compute_F1_scores(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96be178-7b4e-4ea7-9845-10f77f40f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CfwdR9GBlc98Ge10YvGcuCfHbJQ21', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"This is labeled as '2: other'.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1764112877, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=362, total_tokens=371, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "\n",
      "****TRUE LABEL*** 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response_message': \"This is labeled as '2: other'.\",\n",
       " 'true_label': '1',\n",
       " 'tweet_id': '925828356700016643'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell for an example output\n",
    "# Comment out if API Key not available\n",
    "few_shot_with_codebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ce261-e153-4098-bc59-6c1f34f19f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
